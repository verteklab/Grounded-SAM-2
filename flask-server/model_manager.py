import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•ï¼ˆflask-serverï¼‰
current_dir = Path(__file__).parent
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆGrounded-SAM-2ï¼‰
project_root = current_dir.parent
# æ·»åŠ åˆ° sys.path
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import torch
import time
import numpy as np
import threading
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from grounding_dino.groundingdino.util.inference import load_model, load_image_from_base64, predict
from torchvision.ops import box_convert
import logging
from convert import convert_masks_to_json

logger = logging.getLogger(__name__)

class ModelManager:
    """æœ€ç®€å•çš„æ¨¡å‹ç®¡ç†å™¨ - å…¨å±€å•ä¾‹"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.sam2_predictor = None
            self.grounding_model = None
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.models_loaded = False
            self._model_lock = threading.Lock()  # çº¿ç¨‹é”ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
            self._use_thread_pool = False  # æ˜¯å¦ä½¿ç”¨çº¿ç¨‹æ± æ¨¡å¼
            self._thread_pool_manager = None  # çº¿ç¨‹æ± ç®¡ç†å™¨å¼•ç”¨
            self._initialized = True
    
    def load_models(self):
        """ä¸€æ¬¡æ€§åŠ è½½æ¨¡å‹åˆ°å†…å­˜ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬"""
        if self.models_loaded:
            logger.info("æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return
        
        # æ·»åŠ è¿›ç¨‹IDæ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
        logger.info(f"ğŸš€ è¿›ç¨‹ {os.getpid()} å¼€å§‹åŠ è½½æ¨¡å‹åˆ° {self.device}...")
        start_time = time.time()
        
        try:
            with self._model_lock:  # è·å–é”
                # åŒé‡æ£€æŸ¥ï¼šè·å–é”åå†æ¬¡ç¡®è®¤
                if self.models_loaded:
                    logger.info("æ¨¡å‹å·²è¢«å…¶ä»–çº¿ç¨‹åŠ è½½ï¼Œè·³è¿‡")
                    return
                
                # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆç”¨äºæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼‰
                # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆDocker ç¯å¢ƒï¼‰
                project_root = Path(os.getenv('PROJECT_ROOT', Path(__file__).parent.parent))
                
                # åŠ è½½SAM2æ¨¡å‹
                # æ³¨æ„ï¼šbuild_sam2 ä½¿ç”¨ Hydraï¼Œconfig_file åº”è¯¥æ˜¯ Hydra é…ç½®åç§°ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ï¼Œ
                # è€Œä¸æ˜¯ç»å¯¹æ–‡ä»¶è·¯å¾„ã€‚Hydra ä¼šåœ¨å…¶é…ç½®æœç´¢è·¯å¾„ä¸­æŸ¥æ‰¾é…ç½®æ–‡ä»¶ã€‚
                # é…ç½®æ–‡ä»¶å®é™…ä½ç½®ï¼šsam2/configs/sam2.1/sam2.1_hiera_l.yaml
                logger.info("ğŸ“¦ åŠ è½½SAM2æ¨¡å‹...")
                sam2_config_name = os.getenv('SAM2_CONFIG_NAME', "configs/sam2.1/sam2.1_hiera_l.yaml")  # Hydra é…ç½®åç§°ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
                sam2_checkpoint_path = Path(os.getenv('SAM2_CHECKPOINT_PATH',
                    str(project_root / "checkpoints" / "sam2.1_hiera_large.pt")))
                
                logger.info(f"ğŸ“¦ SAM2æ¨¡å‹è·¯å¾„: {sam2_checkpoint_path}")
                sam2_model = build_sam2(
                    sam2_config_name,  # ä½¿ç”¨ Hydra é…ç½®åç§°ï¼Œä¸æ˜¯ç»å¯¹è·¯å¾„
                    str(sam2_checkpoint_path),
                    device=self.device
                )
                self.sam2_predictor = SAM2ImagePredictor(sam2_model)
                
                # åŠ è½½GroundingDINOæ¨¡å‹
                # GroundingDINO çš„ load_model éœ€è¦ç»å¯¹è·¯å¾„
                logger.info("ğŸ“¦ åŠ è½½GroundingDINOæ¨¡å‹...")
                gdino_config_path = Path(os.getenv('GDINO_CONFIG_PATH',
                    str(project_root / "grounding_dino" / "groundingdino" / "config" / "GroundingDINO_SwinT_OGC.py")))
                gdino_checkpoint_path = Path(os.getenv('GDINO_CHECKPOINT_PATH',
                    str(project_root / "gdino_checkpoints" / "groundingdino_swint_ogc.pth")))
                
                logger.info(f"ğŸ“¦ GroundingDINOé…ç½®è·¯å¾„: {gdino_config_path}")
                logger.info(f"ğŸ“¦ GroundingDINOæ¨¡å‹è·¯å¾„: {gdino_checkpoint_path}")
                
                self.grounding_model = load_model(
                    str(gdino_config_path),
                    str(gdino_checkpoint_path),
                    device=self.device
                )
                
                self.models_loaded = True
                load_time = time.time() - start_time
                logger.info(f"âœ… è¿›ç¨‹ {os.getpid()} æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
            
        except Exception as e:
            logger.error(
                f"âŒ è¿›ç¨‹ {os.getpid()} æ¨¡å‹åŠ è½½å¤±è´¥: {e}",
                exc_info=True
            )
            raise
    
    def enable_thread_pool(self, thread_pool_manager):
        """å¯ç”¨çº¿ç¨‹æ± æ¨¡å¼"""
        self._use_thread_pool = True
        self._thread_pool_manager = thread_pool_manager
        logger.info(f"[ModelManager] çº¿ç¨‹æ± æ¨¡å¼å·²å¯ç”¨ (PID={os.getpid()})")
    
    def disable_thread_pool(self):
        """ç¦ç”¨çº¿ç¨‹æ± æ¨¡å¼ï¼Œå›é€€åˆ°é”æ¨¡å¼"""
        self._use_thread_pool = False
        self._thread_pool_manager = None
        logger.info(f"[ModelManager] çº¿ç¨‹æ± æ¨¡å¼å·²ç¦ç”¨ï¼Œå›é€€åˆ°é”æ¨¡å¼ (PID={os.getpid()})")
    
    def inference(self, image_base64, text_prompt="road surface.", box_threshold=0.2, text_threshold=0.25, epsilon=1.0, request_id=None):
        """
        æ‰§è¡Œæ¨ç† - ä½¿ç”¨ Base64 è¾“å…¥ï¼ˆæ”¯æŒçº¿ç¨‹æ± æ¨¡å¼å’Œä¼ ç»Ÿé”æ¨¡å¼ï¼‰
        
        Args:
            image_base64: Base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²
            text_prompt: æ–‡æœ¬æç¤ºï¼ˆéœ€è¦å°å†™å¹¶ä»¥ç‚¹ç»“å°¾ï¼‰
            box_threshold: æ£€æµ‹æ¡†é˜ˆå€¼
            text_threshold: æ–‡æœ¬åŒ¹é…é˜ˆå€¼
            epsilon: å¤šè¾¹å½¢ç®€åŒ–ç²¾åº¦å‚æ•°ï¼ˆé»˜è®¤: 1.0ï¼‰
            request_id: è¯·æ±‚IDï¼ˆç”¨äºæ—¥å¿—è¿½è¸ªï¼‰
        
        Returns:
            æ¨ç†ç»“æœå­—å…¸ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰æˆ–Futureå¯¹è±¡ï¼ˆçº¿ç¨‹æ± æ¨¡å¼ï¼‰
        """
        if not self.models_loaded:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½")
        
        request_id = request_id or "unknown"
        
        # å¦‚æœå¯ç”¨çº¿ç¨‹æ± æ¨¡å¼ï¼Œä½¿ç”¨å¼‚æ­¥æ–¹å¼
        if self._use_thread_pool and self._thread_pool_manager:
            from task_queue import InferenceTask
            from concurrent.futures import Future
            
            # åˆ›å»ºä»»åŠ¡
            task = InferenceTask(
                request_id=request_id,
                image_base64=image_base64,
                text_prompt=text_prompt,
                box_threshold=box_threshold,
                text_threshold=text_threshold,
                epsilon=epsilon
            )
            
            # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            future = self._thread_pool_manager.submit_task(task)
            
            # ä¸ºäº†ä¿æŒAPIå…¼å®¹æ€§ï¼Œè¿™é‡Œéœ€è¦åŒæ­¥ç­‰å¾…ç»“æœ
            # ä½†å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥è¿”å›Futureè®©è°ƒç”¨æ–¹å¼‚æ­¥å¤„ç†
            try:
                result = future.result(timeout=300.0)  # 300ç§’è¶…æ—¶
                return result
            except Exception as e:
                logger.error(f"[{request_id}] çº¿ç¨‹æ± æ¨ç†å¤±è´¥: {e}", exc_info=True)
                raise
        
        # ä¼ ç»Ÿé”æ¨¡å¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        thread_id = threading.current_thread().ident
        
        # åœ¨æ¨ç†æ—¶ä¹ŸåŠ é”ï¼ˆç‰¹åˆ«æ˜¯å†™æ“ä½œï¼‰
        lock_start = time.time()
        logger.info(
            f"[{request_id}] ğŸ”’ ç­‰å¾…æ¨¡å‹é” | "
            f"PID={os.getpid()} | "
            f"TID={thread_id}"
        )
        
        with self._model_lock:  # è·å–é”
            lock_wait_time = time.time() - lock_start
            if lock_wait_time > 0.1:  # å¦‚æœç­‰å¾…æ—¶é—´è¶…è¿‡100msï¼Œè®°å½•è­¦å‘Š
                logger.warning(
                    f"[{request_id}] âš ï¸ æ¨¡å‹é”ç­‰å¾…æ—¶é—´è¾ƒé•¿ | "
                    f"WaitTime={lock_wait_time:.3f}s | "
                    f"PID={os.getpid()} | "
                    f"TID={thread_id}"
                )
            
            logger.info(
                f"[{request_id}] ğŸ”“ è·å–æ¨¡å‹é”æˆåŠŸ | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            # ==============================
            # é˜¶æ®µ Bï¼šè¯»å–å›¾åƒä¸å‰å¤„ç†ï¼ˆå‚è€ƒ grounded_sam2_local_demo.pyï¼‰
            # ==============================
            stage_start = time.time()
            logger.info(f"[{request_id}] ğŸ“¸ é˜¶æ®µ1: åŠ è½½å›¾åƒ | PID={os.getpid()} | TID={thread_id}")
            
            # ä½¿ç”¨ load_image_from_base64 åŠ è½½å›¾åƒ
            # è¿”å›: (image_source: np.array, image: torch.Tensor)
            image_source, image = load_image_from_base64(image_base64)
            
            # è®°å½•æ¨ç†å‰çš„æ˜¾å­˜ä½¿ç”¨
            if torch.cuda.is_available():
                mem_before = torch.cuda.memory_allocated() / 1024**2  # MB
                logger.debug(f"[{request_id}] æ¨ç†å‰æ˜¾å­˜: {mem_before:.1f} MB")
            
            try:
                # è°ƒç”¨æ— é”ç‰ˆæœ¬çš„æ¨ç†æ–¹æ³•
                result = self._inference_without_lock(
                    image_source=image_source,
                    image=image,
                    text_prompt=text_prompt,
                    box_threshold=box_threshold,
                    text_threshold=text_threshold,
                    epsilon=epsilon,
                    request_id=request_id
                )
                
                # è®°å½•æ¨ç†åçš„æ˜¾å­˜ä½¿ç”¨
                if torch.cuda.is_available():
                    mem_after = torch.cuda.memory_allocated() / 1024**2  # MB
                    logger.debug(f"[{request_id}] æ¨ç†åæ˜¾å­˜: {mem_after:.1f} MB (å˜åŒ–: {mem_after - mem_before:+.1f} MB)")
                
                return result
            finally:
                # ç¡®ä¿image tensorè¢«æ¸…ç†ï¼ˆå¦‚æœè¿˜åœ¨GPUä¸Šï¼‰
                if isinstance(image, torch.Tensor) and image.is_cuda:
                    del image
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
    
    def _inference_without_lock(self, image_source, image, text_prompt="road surface.", box_threshold=0.2, text_threshold=0.25, epsilon=1.0, request_id=None):
        """
        æ¨ç†æ–¹æ³•ï¼ˆç”±GPUå·¥ä½œçº¿ç¨‹è°ƒç”¨ï¼‰
        
        æ³¨æ„ï¼šè™½ç„¶æ–¹æ³•åå«"without_lock"ï¼Œä½†å®é™…ä¸Šæ•´ä¸ªæ¨ç†æµç¨‹éƒ½åœ¨ä¸€ä¸ªé”å†…æ‰§è¡Œï¼Œ
        ç¡®ä¿set_imageå’Œpredictä¹‹é—´çš„åŸå­æ€§ï¼Œé¿å…è¢«å…¶ä»–çº¿ç¨‹æ‰“æ–­ã€‚
        
        Args:
            image_source: numpyæ•°ç»„æ ¼å¼çš„å›¾åƒï¼ˆRGBï¼‰
            image: torch.Tensoræ ¼å¼çš„å›¾åƒï¼ˆå·²é¢„å¤„ç†ï¼‰
            text_prompt: æ–‡æœ¬æç¤º
            box_threshold: æ£€æµ‹æ¡†é˜ˆå€¼
            text_threshold: æ–‡æœ¬åŒ¹é…é˜ˆå€¼
            epsilon: å¤šè¾¹å½¢ç®€åŒ–ç²¾åº¦å‚æ•°
            request_id: è¯·æ±‚ID
        
        Returns:
            æ¨ç†ç»“æœå­—å…¸
        """
        request_id = request_id or "unknown"
        thread_id = threading.current_thread().ident
        inference_start = time.time()
        
        image_h, image_w = image_source.shape[:2]
        
        # ==============================
        # å…³é”®ä¿®å¤ï¼šå°†æ•´ä¸ªæ¨ç†æµç¨‹ï¼ˆset_image + GroundingDINO + predictï¼‰æ”¾åœ¨ä¸€ä¸ªé”å†…
        # è¿™æ ·å¯ä»¥ç¡®ä¿åŸå­æ€§ï¼Œé¿å…set_imageå’Œpredictä¹‹é—´è¢«å…¶ä»–çº¿ç¨‹æ‰“æ–­
        # ==============================
        with self._model_lock:
            # ==============================
            # é˜¶æ®µ Bï¼šè®¾ç½®SAM2å›¾åƒåµŒå…¥
            # ==============================
            stage_start = time.time()
            logger.info(f"[{request_id}] ğŸ§  é˜¶æ®µ2: è®¾ç½®SAM2å›¾åƒåµŒå…¥ | PID={os.getpid()} | TID={thread_id}")
            
            try:
                self.sam2_predictor.set_image(image_source)
                # éªŒè¯set_imageæ˜¯å¦æˆåŠŸ
                if not hasattr(self.sam2_predictor, '_is_image_set') or not self.sam2_predictor._is_image_set:
                    raise RuntimeError("set_imageæ‰§è¡Œå_is_image_setä»ä¸ºFalse")
            except Exception as e:
                logger.error(f"[{request_id}] âŒ SAM2å›¾åƒåµŒå…¥å¤±è´¥: {e}", exc_info=True)
                raise
            
            embed_time = time.time() - stage_start
            logger.info(
                f"[{request_id}] âœ… SAM2å›¾åƒåµŒå…¥å®Œæˆ | "
                f"Duration={embed_time:.3f}s"
            )
            
            # ==============================
            # é˜¶æ®µ Cï¼šGroundingDINO æ£€æµ‹ï¼ˆæ–‡æœ¬â†’æ£€æµ‹æ¡†ï¼‰
            # ==============================
            stage_start = time.time()
            logger.info(
                f"[{request_id}] ğŸ” é˜¶æ®µ3: GroundingDINOæ£€æµ‹ | "
                f"Prompt='{text_prompt}' | "
                f"BoxThresh={box_threshold} | "
                f"TextThresh={text_threshold} | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            # GroundingDINOæ£€æµ‹
            # æ³¨æ„ï¼šGroundingDINOæ¨¡å‹åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„
            # æ¨¡å‹çš„forwardæ–¹æ³•ä¼šè°ƒç”¨set_image_tensor/unset_image_tensorï¼Œè¿™äº›æ“ä½œä¼šä¿®æ”¹æ¨¡å‹å†…éƒ¨çŠ¶æ€
            debug_box_threshold = 0.01  # éå¸¸ä½çš„é˜ˆå€¼ï¼Œç”¨äºæŸ¥çœ‹æ‰€æœ‰å¯èƒ½çš„æ£€æµ‹
            
            # æ·»åŠ è¯¦ç»†è¯Šæ–­ï¼šç›´æ¥è°ƒç”¨æ¨¡å‹æŸ¥çœ‹åŸå§‹è¾“å‡º
            try:
                import torch
                with torch.no_grad():
                    # ç›´æ¥è°ƒç”¨æ¨¡å‹ï¼ŒæŸ¥çœ‹åŸå§‹logits
                    outputs_raw = self.grounding_model(image[None], captions=[text_prompt.lower().strip() + ("." if not text_prompt.endswith(".") else "")])
                    prediction_logits_raw = outputs_raw["pred_logits"].cpu().sigmoid()[0]  # (nq, 256)
                    max_logits_per_query = prediction_logits_raw.max(dim=1)[0]  # (nq,)
                    
                    # è®°å½•åŸå§‹logitsç»Ÿè®¡ä¿¡æ¯
                    if len(max_logits_per_query) > 0:
                        max_logit_value = float(max_logits_per_query.max())
                        mean_logit_value = float(max_logits_per_query.mean())
                        logger.info(
                            f"[{request_id}] ğŸ” æ¨¡å‹åŸå§‹è¾“å‡ºè¯Šæ–­: "
                            f"Queries={len(max_logits_per_query)}, "
                            f"MaxLogit={max_logit_value:.6f}, "
                            f"MeanLogit={mean_logit_value:.6f}, "
                            f"MaxLogitAbove0.01={int((max_logits_per_query > 0.01).sum())}, "
                            f"MaxLogitAbove0.001={int((max_logits_per_query > 0.001).sum())}"
                        )
                    else:
                        logger.warning(f"[{request_id}] âš ï¸ æ¨¡å‹è¿”å›ç©ºçš„logitsï¼Œå¯èƒ½æ˜¯æ¨¡å‹çŠ¶æ€å¼‚å¸¸")
            except Exception as e:
                logger.warning(f"[{request_id}] âš ï¸ æ— æ³•è·å–æ¨¡å‹åŸå§‹è¾“å‡º: {e}")
            
            # ä½¿ç”¨debugé˜ˆå€¼è¿›è¡Œæ£€æµ‹
            boxes_debug, confidences_debug, labels_debug = predict(
                model=self.grounding_model,
                image=image,
                caption=text_prompt,
                box_threshold=debug_box_threshold,
                text_threshold=0.01,  # ä¹Ÿé™ä½text_threshold
                device=self.device
            )
            
            # ä½¿ç”¨å®é™…é˜ˆå€¼è¿›è¡Œæ£€æµ‹
            boxes, confidences, labels = predict(
                model=self.grounding_model,
                image=image,
                caption=text_prompt,
                box_threshold=box_threshold,
                text_threshold=text_threshold,
                device=self.device
            )
            
            # è®¡ç®—æ£€æµ‹è€—æ—¶ï¼ˆåœ¨é”å†…è®¡ç®—ï¼Œä½†æ—¥å¿—è®°å½•åœ¨é”å¤–ï¼‰
            detect_time = time.time() - stage_start
        
        # è®°å½•åŸå§‹æ£€æµ‹ç»“æœï¼ˆåœ¨é”å¤–ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”ï¼‰
        if len(boxes_debug) > 0:
            conf_debug_min = float(confidences_debug.min()) if hasattr(confidences_debug, 'min') else float(min(confidences_debug))
            conf_debug_max = float(confidences_debug.max()) if hasattr(confidences_debug, 'max') else float(max(confidences_debug))
            logger.info(
                f"[{request_id}] ğŸ” åŸå§‹æ£€æµ‹ç»“æœï¼ˆbox_threshold=0.01ï¼‰: "
                f"Detected={len(boxes_debug)} boxes, "
                f"ConfidenceRange=[{conf_debug_min:.3f}, {conf_debug_max:.3f}]"
            )
        else:
            logger.warning(
                f"[{request_id}] âš ï¸ å³ä½¿ä½¿ç”¨æä½é˜ˆå€¼(box_threshold=0.01)ä¹Ÿæœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œ"
                f"å¯èƒ½æ˜¯text_prompt='{text_prompt}'ä¸å›¾ç‰‡å†…å®¹ä¸åŒ¹é…ï¼Œæˆ–æ¨¡å‹è¾“å‡ºlogitså…¨éƒ¨å°äº0.01"
            )
        
        # è®°å½•è¯¦ç»†çš„æ£€æµ‹ä¿¡æ¯ï¼ˆåœ¨é”å¤–ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”ï¼‰
        if len(boxes) == 0:
            if len(boxes_debug) > 0:
                # æœ‰åŸå§‹æ£€æµ‹ç»“æœä½†è¢«è¿‡æ»¤æ‰äº†
                conf_debug_max = float(confidences_debug.max()) if hasattr(confidences_debug, 'max') else float(max(confidences_debug))
                logger.warning(
                    f"[{request_id}] âš ï¸ GroundingDINOæ£€æµ‹å®Œæˆä½†æœªæ‰¾åˆ°ç›®æ ‡ | "
                    f"Detected=0 boxes (è¿‡æ»¤å) | "
                    f"åŸå§‹æ£€æµ‹={len(boxes_debug)} boxes, æœ€é«˜ç½®ä¿¡åº¦={conf_debug_max:.3f} | "
                    f"Duration={detect_time:.3f}s | "
                    f"æç¤º: å½“å‰box_threshold={box_threshold}å¤ªé«˜ï¼Œå»ºè®®é™ä½åˆ°{max(0.01, conf_debug_max * 0.8):.3f}ä»¥ä¸‹"
                )
            else:
                # å®Œå…¨æ²¡æœ‰æ£€æµ‹ç»“æœ
                logger.warning(
                    f"[{request_id}] âš ï¸ GroundingDINOæ£€æµ‹å®Œæˆä½†æœªæ‰¾åˆ°ç›®æ ‡ | "
                    f"Detected=0 boxes | "
                    f"Duration={detect_time:.3f}s | "
                    f"æç¤º: å°è¯•è°ƒæ•´text_prompt (å½“å‰='{text_prompt}') æˆ–æ£€æŸ¥å›¾ç‰‡å†…å®¹"
                )
            
            # æå‰è¿”å›ï¼Œé¿å…å¤„ç†ç©ºçš„boxes
            h, w, _ = image_source.shape
            return {
                "status": "success",
                "results": [],
                "count": 0,
                "image_shape": {
                    "width": w,
                    "height": h
                },
                "message": "æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡"
            }
        else:
            # è®°å½•ç½®ä¿¡åº¦èŒƒå›´
            if len(confidences) > 0:
                conf_min = float(confidences.min()) if hasattr(confidences, 'min') else float(min(confidences))
                conf_max = float(confidences.max()) if hasattr(confidences, 'max') else float(max(confidences))
                conf_mean = float(confidences.mean()) if hasattr(confidences, 'mean') else float(sum(confidences) / len(confidences))
                logger.info(
                    f"[{request_id}] âœ… GroundingDINOæ£€æµ‹å®Œæˆ | "
                    f"Detected={len(boxes)} boxes | "
                    f"ConfidenceRange=[{conf_min:.3f}, {conf_max:.3f}], Mean={conf_mean:.3f} | "
                    f"Duration={detect_time:.3f}s"
                )
            else:
                logger.info(
                    f"[{request_id}] âœ… GroundingDINOæ£€æµ‹å®Œæˆ | "
                    f"Detected={len(boxes)} boxes | "
                    f"Duration={detect_time:.3f}s"
                )
        
        # å¤„ç†è¾¹ç•Œæ¡†ï¼šå°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åƒç´ åæ ‡
        h, w, _ = image_source.shape
        # ç¡®ä¿Tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if isinstance(boxes, torch.Tensor):
            boxes = boxes * torch.Tensor([w, h, w, h]).to(boxes.device)
        else:
            boxes = boxes * torch.Tensor([w, h, w, h])
        
        input_boxes = box_convert(boxes=boxes, in_fmt="cxcywh", out_fmt="xyxy").numpy()
        
        # ç«‹å³æ¸…ç†GPU tensorï¼ˆGroundingDINOçš„boxeså¯èƒ½åœ¨GPUä¸Šï¼‰
        if isinstance(boxes, torch.Tensor):
            del boxes
        if isinstance(confidences, torch.Tensor):
            confidences = confidences.cpu().numpy()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # å†æ¬¡æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœï¼ˆåŒé‡ä¿é™©ï¼‰
        if len(input_boxes) == 0:
            logger.info(
                f"[{request_id}] âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ | "
                f"ImageSize={w}x{h}"
            )
            return {
                "status": "success",
                "results": [],
                "count": 0,
                "image_shape": {
                    "width": w,
                    "height": h
                },
                "message": "æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡"
            }
        
        # ==============================
        # é˜¶æ®µ Dï¼šSAM2 åˆ†å‰²ï¼ˆæ¡†â†’maskï¼‰
        # ==============================
        stage_start = time.time()
        logger.info(
            f"[{request_id}] ğŸ¯ é˜¶æ®µ4: SAM2åˆ†å‰² | "
            f"Boxes={len(input_boxes)} | "
            f"PID={os.getpid()} | "
            f"TID={thread_id}"
        )
        
        # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆbfloat16ï¼‰
        if torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
        
        # SAM2åˆ†å‰²
        # æ³¨æ„ï¼špredictå¿…é¡»åœ¨é”å†…æ‰§è¡Œï¼Œç¡®ä¿ä¸set_imageçš„åŸå­æ€§
        # ä½†æ˜¯ï¼Œç”±äºæ•´ä¸ªæ¨ç†æµç¨‹ï¼ˆset_image + GroundingDINO + predictï¼‰éƒ½åœ¨é”å†…ï¼Œ
        # è¿™é‡Œéœ€è¦é‡æ–°è·å–é”ï¼Œå› ä¸ºä¹‹å‰çš„é”å·²ç»é‡Šæ”¾äº†
        try:
            with self._model_lock:
                # éªŒè¯çŠ¶æ€ï¼ˆåœ¨é”å†…æ£€æŸ¥ï¼Œç¡®ä¿åŸå­æ€§ï¼‰
                if not hasattr(self.sam2_predictor, '_is_image_set') or not self.sam2_predictor._is_image_set:
                    raise RuntimeError("è°ƒç”¨predictå‰_is_image_setä¸ºFalseï¼ŒçŠ¶æ€å¼‚å¸¸ï¼ˆå¯èƒ½è¢«å…¶ä»–çº¿ç¨‹çš„set_imageæ‰“æ–­ï¼‰")
                
                if not hasattr(self.sam2_predictor, '_orig_hw') or self.sam2_predictor._orig_hw is None:
                    raise RuntimeError("è°ƒç”¨predictå‰_orig_hwä¸ºNoneï¼ŒçŠ¶æ€å¼‚å¸¸ï¼ˆå¯èƒ½è¢«å…¶ä»–çº¿ç¨‹çš„set_imageæ‰“æ–­ï¼‰")
                
                # åœ¨é”å†…è°ƒç”¨predictï¼Œç¡®ä¿ä¸set_imageçš„åŸå­æ€§
                with torch.autocast(device_type=self.device, dtype=torch.bfloat16):
                    predict_result = self.sam2_predictor.predict(
                        point_coords=None,
                        point_labels=None,
                        box=input_boxes,
                        multimask_output=False,
                    )
            
            # æ£€æŸ¥predictè¿”å›å€¼ï¼ˆåœ¨é”å¤–æ£€æŸ¥ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”ï¼‰
            if predict_result is None:
                raise RuntimeError("SAM2 predictè¿”å›None")
            
            masks, scores, logits = predict_result
            
            # æ£€æŸ¥è¿”å›å€¼æ˜¯å¦æœ‰æ•ˆ
            if masks is None:
                raise RuntimeError("SAM2 predictè¿”å›çš„masksä¸ºNone")
            if scores is None:
                raise RuntimeError("SAM2 predictè¿”å›çš„scoresä¸ºNone")
            if logits is None:
                raise RuntimeError("SAM2 predictè¿”å›çš„logitsä¸ºNone")
                
        except Exception as e:
            logger.error(f"[{request_id}] âŒ SAM2åˆ†å‰²å¤±è´¥: {e}", exc_info=True)
            raise
        
        segment_time = time.time() - stage_start
        logger.info(
            f"[{request_id}] âœ… SAM2åˆ†å‰²å®Œæˆ | "
            f"Masks={len(masks) if hasattr(masks, '__len__') else 'N/A'} | "
            f"Duration={segment_time:.3f}s"
        )
        
        # è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆå¦‚æœæ˜¯ torch.Tensorï¼‰
        # æ³¨æ„ï¼šå…ˆè½¬æ¢å†åˆ é™¤ï¼Œé¿å…tensorç•™åœ¨GPU
        masks_numpy = None
        scores_numpy = None
        
        # ç«‹å³é‡Šæ”¾logitsï¼ˆæˆ‘ä»¬ä¸éœ€è¦logitsï¼Œåªä¿ç•™maskså’Œscoresï¼‰
        if isinstance(logits, torch.Tensor):
            del logits
            logits = None
        
        if isinstance(masks, torch.Tensor):
            masks_numpy = masks.cpu().numpy()
            del masks  # ç«‹å³åˆ é™¤GPU tensor
            masks = masks_numpy
        if isinstance(scores, torch.Tensor):
            scores_numpy = scores.cpu().numpy()
            del scores  # ç«‹å³åˆ é™¤GPU tensor
            scores = scores_numpy
        
        # æ¸…ç†GPUæ˜¾å­˜ï¼šé‡Šæ”¾æ¨ç†è¿‡ç¨‹ä¸­çš„ä¸´æ—¶tensor
        if torch.cuda.is_available():
            torch.cuda.synchronize()  # å…ˆåŒæ­¥ï¼Œç¡®ä¿æ‰€æœ‰æ“ä½œå®Œæˆ
            torch.cuda.empty_cache()  # å†æ¸…ç†ç¼“å­˜
        
        # å¤„ç†å¤šmaskè¾“å‡º
        if masks.ndim == 4 and masks.shape[1] > 1:
            best = np.argmax(scores, axis=1)
            masks = masks[np.arange(masks.shape[0]), best]
        
        # è½¬æ¢ä¸º (n, H, W) æ ¼å¼
        if masks.ndim == 4:
            masks = masks.squeeze(1)
        elif masks.ndim == 2:
            masks = masks[np.newaxis, :, :]
        
        # ç¡®ä¿ masks æ˜¯ 3ç»´æ•°ç»„ (n, H, W)
        assert masks.ndim == 3, f"masks åº”è¯¥æ˜¯3ç»´æ•°ç»„ (n, H, W)ï¼Œä½†å¾—åˆ° {masks.ndim} ç»´ï¼Œå½¢çŠ¶: {masks.shape}"
        
        # ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
        n_masks = masks.shape[0]
        n_boxes = len(input_boxes)
        n_labels = len(labels)
        n_confidences = len(confidences)
        
        if not (n_masks == n_boxes == n_labels == n_confidences):
            logger.warning(f"æ•°ç»„é•¿åº¦ä¸ä¸€è‡´: masks={n_masks}, boxes={n_boxes}, labels={n_labels}, confidences={n_confidences}")
            min_len = min(n_masks, n_boxes, n_labels, n_confidences)
            masks = masks[:min_len]
            input_boxes = input_boxes[:min_len]
            labels = labels[:min_len]
            confidences = confidences[:min_len]
        
        # ==============================
        # é˜¶æ®µ Eï¼šç»“æœæ ¼å¼åŒ– - ä½¿ç”¨convert_masks_to_jsonè½¬æ¢ä¸ºå¤šè¾¹å½¢æ ¼å¼
        # ==============================
        stage_start = time.time()
        logger.info(f"[{request_id}] ğŸ“¦ é˜¶æ®µ5: æ ¼å¼åŒ–ç»“æœï¼ˆè½¬æ¢ä¸ºå¤šè¾¹å½¢æ ¼å¼ï¼‰ | PID={os.getpid()} | TID={thread_id}")
        
        # ç¡®ä¿masksæ˜¯numpyæ•°ç»„æ ¼å¼ï¼ˆå¸ƒå°”ç±»å‹ï¼‰
        masks_np = []
        for mask in masks:
            if isinstance(mask, np.ndarray):
                # è½¬æ¢ä¸ºå¸ƒå°”ç±»å‹
                mask_bool = mask.astype(bool)
            else:
                mask_bool = np.array(mask, dtype=bool)
            masks_np.append(mask_bool)
        
        # ç¡®ä¿input_boxesæ˜¯numpyæ•°ç»„æ ¼å¼
        if isinstance(input_boxes, np.ndarray):
            input_boxes_np = input_boxes
        else:
            input_boxes_np = np.array(input_boxes)
        
        # ç¡®ä¿labelsæ˜¯åˆ—è¡¨æ ¼å¼
        if isinstance(labels, np.ndarray):
            labels_list = labels.tolist()
        else:
            labels_list = list(labels)
        
        # ç¡®ä¿confidencesæ˜¯åˆ—è¡¨æ ¼å¼ï¼ˆfloatï¼‰
        confidences_list = []
        for conf in confidences:
            if isinstance(conf, (torch.Tensor, np.ndarray)):
                conf = float(conf.item() if hasattr(conf, 'item') else conf)
            else:
                conf = float(conf)
            confidences_list.append(conf)
        
        # ä½¿ç”¨convert_masks_to_jsonè½¬æ¢ä¸ºå¤šè¾¹å½¢æ ¼å¼
        try:
            # åœ¨è½¬æ¢å‰æ¸…ç†æ˜¾å­˜ï¼ˆmasks_npå¯èƒ½å¾ˆå¤§ï¼‰
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            result_dict = convert_masks_to_json(
                masks=masks_np,
                input_boxes=input_boxes_np,
                labels=labels_list,
                confidences=confidences_list,
                w=w,
                h=h,
                epsilon=epsilon,
                enable_visualization=False
            )
            
            # è½¬æ¢åç«‹å³æ¸…ç†ä¸´æ—¶å˜é‡
            del masks_np, input_boxes_np, labels_list, confidences_list
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            format_time = time.time() - stage_start
            
            logger.info(
                f"[{request_id}] âœ… ç»“æœæ ¼å¼åŒ–å®Œæˆï¼ˆå¤šè¾¹å½¢æ ¼å¼ï¼‰ | "
                f"Count={result_dict.get('count', 0)} | "
                f"FormatTime={format_time:.3f}s | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
        except Exception as e:
            logger.error(
                f"[{request_id}] âŒ ç»“æœæ ¼å¼åŒ–å¤±è´¥: {e}",
                exc_info=True
            )
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå§‹æ ¼å¼ä½œä¸ºé™çº§æ–¹æ¡ˆ
            format_time = time.time() - stage_start
            masks_list = []
            for mask in masks:
                masks_list.append(mask.astype(int).tolist())
            
            input_boxes_list = input_boxes.tolist() if isinstance(input_boxes, np.ndarray) else list(input_boxes)
            
            result_dict = {
                "status": "error",
                "message": f"æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå§‹æ ¼å¼: {str(e)}"
            }
            logger.warning(f"[{request_id}] ä½¿ç”¨åŸå§‹æ ¼å¼ä½œä¸ºé™çº§æ–¹æ¡ˆ")
        
        # æœ€ç»ˆæ¸…ç†ï¼šé‡Šæ”¾æ‰€æœ‰ä¸´æ—¶å˜é‡å’ŒGPUæ˜¾å­˜
        # æ³¨æ„ï¼šæŒ‰é¡ºåºåˆ é™¤ï¼Œå…ˆåˆ é™¤å¤§çš„tensor
        if torch.cuda.is_available():
            mem_before_cleanup = torch.cuda.memory_allocated() / 1024**2  # MB
            
            # æ¸…ç†æ‰€æœ‰å¯èƒ½ç•™åœ¨GPUçš„tensor
            if 'logits' in locals() and logits is not None:
                if isinstance(logits, torch.Tensor):
                    del logits
                logits = None
            if 'masks' in locals() and isinstance(masks, torch.Tensor):
                del masks
            if 'scores' in locals() and isinstance(scores, torch.Tensor):
                del scores
            if 'image' in locals() and isinstance(image, torch.Tensor):
                if image.is_cuda:
                    del image
            if 'boxes' in locals() and isinstance(boxes, torch.Tensor):
                if boxes.is_cuda:
                    del boxes
            
            # æ¸…ç†SAM2 predictorçš„å›¾åƒåµŒå…¥ç¼“å­˜ï¼ˆé‡è¦ï¼ï¼‰
            # è¿™ä¼šé‡Šæ”¾set_imageæ—¶åˆ›å»ºçš„å›¾åƒåµŒå…¥ç‰¹å¾
            try:
                self.sam2_predictor.reset_predictor()
            except Exception as e:
                logger.warning(f"[{request_id}] æ¸…ç†SAM2 predictorç¼“å­˜å¤±è´¥: {e}")
            
            # å¼ºåˆ¶åŒæ­¥å¹¶æ¸…ç†ç¼“å­˜
            torch.cuda.synchronize()
            torch.cuda.empty_cache()
            
            mem_after_cleanup = torch.cuda.memory_allocated() / 1024**2  # MB
            freed_memory = mem_before_cleanup - mem_after_cleanup
            if freed_memory > 10:  # å¦‚æœé‡Šæ”¾äº†è¶…è¿‡10MBï¼Œè®°å½•æ—¥å¿—
                logger.info(f"[{request_id}] ğŸ§¹ æ˜¾å­˜æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾äº† {freed_memory:.1f} MB (æ¸…ç†å‰: {mem_before_cleanup:.1f} MB, æ¸…ç†å: {mem_after_cleanup:.1f} MB)")
        
        # æ¸…ç†CPUå˜é‡
        if 'image_source' in locals():
            del image_source
        if 'input_boxes' in locals():
            del input_boxes
        if 'labels' in locals():
            del labels
        if 'confidences' in locals():
            del confidences
        if 'masks' in locals():
            del masks
        if 'scores' in locals():
            del scores
        if 'logits' in locals():
            logits = None
            
        total_inference_time = time.time() - inference_start
        
        logger.info(
            f"[{request_id}] âœ… æ¨ç†å®Œæˆ | "
            f"TotalTime={total_inference_time:.3f}s | "
            f"PID={os.getpid()} | "
            f"TID={thread_id}"
        )
        
        return result_dict
#         #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”return______________________________________________
#         # ==============================
#         # é˜¶æ®µ Fï¼šç»“æœå¤„ç†ä¸æ ¼å¼åŒ–
#         # ==============================
#         # è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼ï¼ˆå‚è€ƒ grounded_sam2_local_demo.py çš„å¤šè¾¹å½¢æ ¼å¼ï¼‰
#         results = []
#         for idx in range(len(masks)):
#             mask = masks[idx]
#             box = input_boxes[idx]
#             label = labels[idx]
#             confidence = confidences[idx]
            
#             # ç¡®ä¿ mask æ˜¯å¸ƒå°”ç±»å‹æˆ–å¯ä»¥è½¬æ¢ä¸ºå¸ƒå°”ç±»å‹
#             if isinstance(confidence, torch.Tensor):
#                 confidence = confidence.item() if confidence.numel() == 1 else float(confidence)
#             else:
#                 confidence = float(confidence)
            
#             # æå–å¤šè¾¹å½¢è½®å»“ï¼ˆä½¿ç”¨ä¸ grounded_sam2_local_demo.py ç›¸åŒçš„æ–¹æ³•ï¼‰
#             polygon = self._mask_to_polygon_json(mask, box, label, confidence, idx + 1, epsilon=epsilon)
            
#             if polygon is not None:
#                 results.append({
#                     "id": polygon.get("id"),
#                     "type": polygon.get("type"),
#                     "points": polygon.get("points"),
#                     "label": polygon.get("label"),
#                     "score": polygon.get("score"),
#                     "order": polygon.get("order"),
#                     "bbox": box.tolist() if isinstance(box, np.ndarray) else list(box)
#                 })
        
#         return {
#             "status": "success",
#             "results": results,
#             "count": len(results),
#             "image_shape": {
#                 "width": w,
#                 "height": h
#             }
#         }
        
#     except Exception as e:
#         logger.error(f"æ¨ç†å¤±è´¥: {e}")
#         import traceback
#         logger.error(traceback.format_exc())
#         return {"status": "error", "message": str(e)}

# def _mask_to_polygon_json(self, mask, box, label, score, order, epsilon=1.0):
#     """
#     å°† mask è½¬æ¢ä¸ºå‰ç«¯å¤šè¾¹å½¢ JSON æ ¼å¼ï¼ˆå‚è€ƒ grounded_sam2_local_demo.pyï¼‰
    
#     Args:
#         mask: å…¨å›¾å°ºå¯¸çš„å¸ƒå°” mask (H, W)
#         box: è¾¹ç•Œæ¡† (x1, y1, x2, y2) åŸå›¾åæ ‡ç³»
#         label: ç±»åˆ«æ ‡ç­¾
#         score: æ£€æµ‹æ¡†ç½®ä¿¡åº¦åˆ†æ•°
#         order: é¡ºåºç¼–å·
#         epsilon: å¤šè¾¹å½¢ç®€åŒ–ç²¾åº¦å‚æ•°
    
#     Returns:
#         polygon_json: å‰ç«¯å¤šè¾¹å½¢ JSON å¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æœ‰æ•ˆè½®å»“åˆ™è¿”å› None
#     """
#     try:
#         import cv2
#         import random
#         import string
        
#         def generate_random_id():
#             """ç”Ÿæˆéšæœº ID"""
#             chars = string.digits + string.ascii_lowercase
#             return ''.join(random.choices(chars, k=11))
        
#         def extract_mask_contour_from_box(mask, box):
#             """ä»å…¨å›¾ mask ä¸­æå–æ¡†å†…åŒºåŸŸçš„è½®å»“"""
#             # ç¡®ä¿ mask æ˜¯ numpy æ•°ç»„
#             if not isinstance(mask, np.ndarray):
#                 mask = np.array(mask)
            
#             # ç¡®ä¿ mask æ˜¯2ç»´æ•°ç»„
#             if mask.ndim != 2:
#                 if mask.ndim == 3:
#                     mask = mask.squeeze(0)
#                 else:
#                     raise ValueError(f"mask åº”è¯¥æ˜¯2ç»´æ•°ç»„ (H, W)ï¼Œä½†å¾—åˆ° {mask.ndim} ç»´ï¼Œå½¢çŠ¶: {mask.shape}")
            
#             # ç¡®ä¿ box æ˜¯ numpy æ•°ç»„å¹¶è½¬æ¢ä¸ºæ•´æ•°
#             if not isinstance(box, np.ndarray):
#                 box = np.array(box)
#             x1, y1, x2, y2 = box.astype(int)
            
#             # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
#             mask_h, mask_w = mask.shape
#             x1_actual = max(0, min(x1, mask_w - 1))
#             y1_actual = max(0, min(y1, mask_h - 1))
#             x2_actual = max(x1_actual + 1, min(x2, mask_w))
#             y2_actual = max(y1_actual + 1, min(y2, mask_h))
            
#             actual_box = np.array([x1_actual, y1_actual, x2_actual, y2_actual])
            
#             # æ£€æŸ¥è£å‰ªåŒºåŸŸæ˜¯å¦æœ‰æ•ˆ
#             if x2_actual <= x1_actual or y2_actual <= y1_actual:
#                 return [], actual_box
            
#             # è£å‰ªåˆ°æ¡†å†…åŒºåŸŸï¼ˆæ³¨æ„ï¼šmask ç´¢å¼•æ˜¯ [y, x] é¡ºåºï¼‰
#             box_mask = mask[y1_actual:y2_actual, x1_actual:x2_actual].astype(np.uint8) * 255
            
#             if box_mask.sum() == 0:
#                 return [], actual_box
            
#             # æå–è½®å»“ï¼ˆåªæå–å¤–éƒ¨è½®å»“ï¼‰
#             contours, _ = cv2.findContours(box_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            
#             contour_list = []
#             for contour in contours:
#                 if len(contour) >= 3:
#                     contour_2d = contour.reshape(-1, 2).astype(float)
#                     contour_list.append(contour_2d)
            
#             return contour_list, actual_box
        
#         def simplify_polygon(contour, epsilon=2.0):
#             """ä½¿ç”¨ Douglas-Peucker ç®—æ³•ç®€åŒ–å¤šè¾¹å½¢"""
#             # ç¡®ä¿ contour æ˜¯ numpy æ•°ç»„
#             if not isinstance(contour, np.ndarray):
#                 contour = np.array(contour)
            
#             # æ£€æŸ¥ contour æ˜¯å¦æœ‰æ•ˆ
#             if len(contour) < 3:
#                 return contour
            
#             # ç¡®ä¿ contour æ˜¯2ç»´æ•°ç»„ (N, 2)
#             if contour.ndim == 1:
#                 if len(contour) == 2:
#                     contour = contour.reshape(1, 2)
#                 else:
#                     raise ValueError(f"contour å½¢çŠ¶æ— æ•ˆ: {contour.shape}")
#             elif contour.ndim == 2:
#                 if contour.shape[1] != 2:
#                     raise ValueError(f"contour åº”è¯¥æ˜¯ (N, 2) å½¢çŠ¶ï¼Œä½†å¾—åˆ° {contour.shape}")
#             else:
#                 raise ValueError(f"contour åº”è¯¥æ˜¯2ç»´æ•°ç»„ï¼Œä½†å¾—åˆ° {contour.ndim} ç»´")
            
#             # è½¬æ¢ä¸ºæ•´æ•°ç±»å‹ï¼ˆOpenCV è¦æ±‚ï¼‰
#             contour_int = contour.astype(np.int32)
            
#             # è½¬æ¢ä¸º OpenCV è¦æ±‚çš„æ ¼å¼ (N, 1, 2)
#             if contour_int.ndim == 2:
#                 contour_int = contour_int.reshape(-1, 1, 2)
            
#             # è®¡ç®—ç®€åŒ–å‚æ•°
#             epsilon_val = epsilon * cv2.arcLength(contour_int, closed=True) / 100.0
            
#             # æ‰§è¡Œå¤šè¾¹å½¢ç®€åŒ–
#             simplified = cv2.approxPolyDP(contour_int, epsilon_val, closed=True)
            
#             # è½¬æ¢å› (N, 2) æ ¼å¼å¹¶è¿”å›æµ®ç‚¹ç±»å‹
#             if simplified.shape[0] == 0:
#                 return contour  # å¦‚æœç®€åŒ–åä¸ºç©ºï¼Œè¿”å›åŸå§‹è½®å»“
            
#             return simplified.reshape(-1, 2).astype(float)
        
#         def local_to_global_coords(local_points, box, actual_box):
#             """å°†æ¡†å±€éƒ¨åæ ‡ç³»è½¬æ¢ä¸ºåŸå›¾å…¨å±€åæ ‡ç³»"""
#             # ç¡®ä¿è¾“å…¥æ˜¯ numpy æ•°ç»„
#             if not isinstance(local_points, np.ndarray):
#                 local_points = np.array(local_points)
#             if not isinstance(box, np.ndarray):
#                 box = np.array(box)
#             if not isinstance(actual_box, np.ndarray):
#                 actual_box = np.array(actual_box)
            
#             # ç¡®ä¿ local_points æ˜¯2ç»´æ•°ç»„ (N, 2)
#             if local_points.ndim == 1:
#                 local_points = local_points.reshape(1, -1)
#             if local_points.shape[1] != 2:
#                 raise ValueError(f"local_points åº”è¯¥æ˜¯ (N, 2) å½¢çŠ¶ï¼Œä½†å¾—åˆ° {local_points.shape}")
            
#             x1_actual, y1_actual, x2_actual, y2_actual = actual_box.astype(float)
#             actual_box_w = x2_actual - x1_actual
#             actual_box_h = y2_actual - y1_actual
            
#             x1_orig, y1_orig, x2_orig, y2_orig = box.astype(float)
#             orig_box_w = x2_orig - x1_orig
#             orig_box_h = y2_orig - y1_orig
            
#             # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
#             global_points = local_points.copy()
            
#             if actual_box_w != orig_box_w or actual_box_h != orig_box_h:
#                 scale_x = orig_box_w / actual_box_w if actual_box_w > 0 else 1.0
#                 scale_y = orig_box_h / actual_box_h if actual_box_h > 0 else 1.0
#                 # å…ˆç¼©æ”¾
#                 global_points[:, 0] = local_points[:, 0] * scale_x
#                 global_points[:, 1] = local_points[:, 1] * scale_y
#                 # å†å¹³ç§»
#                 global_points[:, 0] = x1_orig + global_points[:, 0]
#                 global_points[:, 1] = y1_orig + global_points[:, 1]
#             else:
#                 # ç›´æ¥å¹³ç§»
#                 global_points[:, 0] = x1_orig + local_points[:, 0]
#                 global_points[:, 1] = y1_orig + local_points[:, 1]
            
#             return global_points
        
#         # æ­¥éª¤1: ä» mask æå–æ¡†å†…è½®å»“
#         contours, actual_box = extract_mask_contour_from_box(mask, box)
        
#         if not contours:
#             return None
        
#         # é€‰æ‹©æœ€å¤§çš„è½®å»“ä½œä¸ºä¸»è¦è½®å»“
#         main_contour = max(contours, key=len)
        
#         # æ­¥éª¤2: ç®€åŒ–è½®å»“
#         simplified_contour = simplify_polygon(main_contour, epsilon=epsilon)
        
#         # æ­¥éª¤3: å±€éƒ¨åæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡
#         global_points = local_to_global_coords(simplified_contour, box, actual_box)
        
#         # æ­¥éª¤4: ç»„è£…å‰ç«¯ JSON
#         polygon_id = generate_random_id()
#         points = [
#             {
#                 "id": generate_random_id(),
#                 "x": float(x),
#                 "y": float(y)
#             }
#             for x, y in global_points
#         ]
        
#         polygon_json = {
#             "id": polygon_id,
#             "type": "line",
#             "points": points,
#             "label": label,
#             "score": float(score),
#             "order": int(order)
#         }
        
#         return polygon_json
        
#     except Exception as e:
#         logger.error(f"å¤šè¾¹å½¢è½¬æ¢å¤±è´¥: {e}")
#         import traceback
#         logger.error(traceback.format_exc())
#         return None

# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
model_manager = ModelManager()