import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•ï¼ˆflask-serverï¼‰
current_dir = Path(__file__).parent
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆGrounded-SAM-2ï¼‰
project_root = current_dir.parent
# æ·»åŠ åˆ° sys.path
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import torch
import time
import numpy as np
import threading
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from grounding_dino.groundingdino.util.inference import load_model, load_image_from_base64, predict
from torchvision.ops import box_convert
import logging

logger = logging.getLogger(__name__)

class ModelManager:
    """æœ€ç®€å•çš„æ¨¡å‹ç®¡ç†å™¨ - å…¨å±€å•ä¾‹"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.sam2_predictor = None
            self.grounding_model = None
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.models_loaded = False
            self._model_lock = threading.Lock()  # çº¿ç¨‹é”
            self._initialized = True
    
    def load_models(self):
        """ä¸€æ¬¡æ€§åŠ è½½æ¨¡å‹åˆ°å†…å­˜ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬"""
        if self.models_loaded:
            logger.info("æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return
        
        # æ·»åŠ è¿›ç¨‹IDæ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
        logger.info(f"ğŸš€ è¿›ç¨‹ {os.getpid()} å¼€å§‹åŠ è½½æ¨¡å‹åˆ° {self.device}...")
        start_time = time.time()
        
        try:
            with self._model_lock:  # è·å–é”
                # åŒé‡æ£€æŸ¥ï¼šè·å–é”åå†æ¬¡ç¡®è®¤
                if self.models_loaded:
                    logger.info("æ¨¡å‹å·²è¢«å…¶ä»–çº¿ç¨‹åŠ è½½ï¼Œè·³è¿‡")
                    return
                
                # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆç”¨äºæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼‰
                project_root = Path(__file__).parent.parent
                
                # åŠ è½½SAM2æ¨¡å‹
                # æ³¨æ„ï¼šbuild_sam2 ä½¿ç”¨ Hydraï¼Œconfig_file åº”è¯¥æ˜¯ Hydra é…ç½®åç§°ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ï¼Œ
                # è€Œä¸æ˜¯ç»å¯¹æ–‡ä»¶è·¯å¾„ã€‚Hydra ä¼šåœ¨å…¶é…ç½®æœç´¢è·¯å¾„ä¸­æŸ¥æ‰¾é…ç½®æ–‡ä»¶ã€‚
                # é…ç½®æ–‡ä»¶å®é™…ä½ç½®ï¼šsam2/configs/sam2.1/sam2.1_hiera_l.yaml
                logger.info("ğŸ“¦ åŠ è½½SAM2æ¨¡å‹...")
                sam2_config_name = "configs/sam2.1/sam2.1_hiera_l.yaml"  # Hydra é…ç½®åç§°ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
                sam2_checkpoint_path = project_root / "checkpoints" / "sam2.1_hiera_large.pt"
                
                sam2_model = build_sam2(
                    sam2_config_name,  # ä½¿ç”¨ Hydra é…ç½®åç§°ï¼Œä¸æ˜¯ç»å¯¹è·¯å¾„
                    str(sam2_checkpoint_path),
                    device=self.device
                )
                self.sam2_predictor = SAM2ImagePredictor(sam2_model)
                
                # åŠ è½½GroundingDINOæ¨¡å‹
                # GroundingDINO çš„ load_model éœ€è¦ç»å¯¹è·¯å¾„
                logger.info("ğŸ“¦ åŠ è½½GroundingDINOæ¨¡å‹...")
                gdino_config_path = project_root / "grounding_dino" / "groundingdino" / "config" / "GroundingDINO_SwinT_OGC.py"
                gdino_checkpoint_path = project_root / "gdino_checkpoints" / "groundingdino_swint_ogc.pth"
                
                self.grounding_model = load_model(
                    str(gdino_config_path),
                    str(gdino_checkpoint_path),
                    device=self.device
                )
                
                self.models_loaded = True
                load_time = time.time() - start_time
                logger.info(f"âœ… è¿›ç¨‹ {os.getpid()} æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
            
        except Exception as e:
            logger.error(
                f"âŒ è¿›ç¨‹ {os.getpid()} æ¨¡å‹åŠ è½½å¤±è´¥: {e}",
                exc_info=True
            )
            raise
    
    def inference(self, image_base64, text_prompt="road surface.", box_threshold=0.2, text_threshold=0.25, epsilon=1.0, request_id=None):
        """
        æ‰§è¡Œæ¨ç† - ä½¿ç”¨ Base64 è¾“å…¥ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰
        
        Args:
            image_base64: Base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²
            text_prompt: æ–‡æœ¬æç¤ºï¼ˆéœ€è¦å°å†™å¹¶ä»¥ç‚¹ç»“å°¾ï¼‰
            box_threshold: æ£€æµ‹æ¡†é˜ˆå€¼
            text_threshold: æ–‡æœ¬åŒ¹é…é˜ˆå€¼
            epsilon: å¤šè¾¹å½¢ç®€åŒ–ç²¾åº¦å‚æ•°ï¼ˆé»˜è®¤: 1.0ï¼‰
            request_id: è¯·æ±‚IDï¼ˆç”¨äºæ—¥å¿—è¿½è¸ªï¼‰
        
        Returns:
            æ¨ç†ç»“æœå­—å…¸
        """
        if not self.models_loaded:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½")
        
        request_id = request_id or "unknown"
        thread_id = threading.current_thread().ident
        
        # åœ¨æ¨ç†æ—¶ä¹ŸåŠ é”ï¼ˆç‰¹åˆ«æ˜¯å†™æ“ä½œï¼‰
        lock_start = time.time()
        logger.info(
            f"[{request_id}] ğŸ”’ ç­‰å¾…æ¨¡å‹é” | "
            f"PID={os.getpid()} | "
            f"TID={thread_id}"
        )
        
        with self._model_lock:  # è·å–é”
            lock_wait_time = time.time() - lock_start
            if lock_wait_time > 0.1:  # å¦‚æœç­‰å¾…æ—¶é—´è¶…è¿‡100msï¼Œè®°å½•è­¦å‘Š
                logger.warning(
                    f"[{request_id}] âš ï¸ æ¨¡å‹é”ç­‰å¾…æ—¶é—´è¾ƒé•¿ | "
                    f"WaitTime={lock_wait_time:.3f}s | "
                    f"PID={os.getpid()} | "
                    f"TID={thread_id}"
                )
            
            logger.info(
                f"[{request_id}] ğŸ”“ è·å–æ¨¡å‹é”æˆåŠŸ | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            # ==============================
            # é˜¶æ®µ Bï¼šè¯»å–å›¾åƒä¸å‰å¤„ç†ï¼ˆå‚è€ƒ grounded_sam2_local_demo.pyï¼‰
            # ==============================
            stage_start = time.time()
            logger.info(f"[{request_id}] ğŸ“¸ é˜¶æ®µ1: åŠ è½½å›¾åƒ | PID={os.getpid()} | TID={thread_id}")
            
            # ä½¿ç”¨ load_image_from_base64 åŠ è½½å›¾åƒ
            # è¿”å›: (image_source: np.array, image: torch.Tensor)
            image_source, image = load_image_from_base64(image_base64)
            image_h, image_w = image_source.shape[:2]
            
            load_time = time.time() - stage_start
            logger.info(
                f"[{request_id}] âœ… å›¾åƒåŠ è½½å®Œæˆ | "
                f"Size={image_w}x{image_h} | "
                f"Duration={load_time:.3f}s"
            )
            
            # è®¾ç½®SAM2å›¾åƒï¼ˆè®¡ç®—å›¾åƒåµŒå…¥ï¼‰
            stage_start = time.time()
            logger.info(f"[{request_id}] ğŸ§  é˜¶æ®µ2: è®¾ç½®SAM2å›¾åƒåµŒå…¥ | PID={os.getpid()} | TID={thread_id}")
            
            self.sam2_predictor.set_image(image_source)
            
            embed_time = time.time() - stage_start
            logger.info(
                f"[{request_id}] âœ… SAM2å›¾åƒåµŒå…¥å®Œæˆ | "
                f"Duration={embed_time:.3f}s"
            )
            
            # ==============================
            # é˜¶æ®µ Cï¼šGroundingDINO æ£€æµ‹ï¼ˆæ–‡æœ¬â†’æ£€æµ‹æ¡†ï¼‰
            # ==============================
            stage_start = time.time()
            logger.info(
                f"[{request_id}] ğŸ” é˜¶æ®µ3: GroundingDINOæ£€æµ‹ | "
                f"Prompt='{text_prompt}' | "
                f"BoxThresh={box_threshold} | "
                f"TextThresh={text_threshold} | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            # GroundingDINOæ£€æµ‹
            boxes, confidences, labels = predict(
                model=self.grounding_model,
                image=image,
                caption=text_prompt,
                box_threshold=box_threshold,
                text_threshold=text_threshold,
                device=self.device
            )
            
            detect_time = time.time() - stage_start
            logger.info(
                f"[{request_id}] âœ… GroundingDINOæ£€æµ‹å®Œæˆ | "
                f"Detected={len(boxes)} boxes | "
                f"Duration={detect_time:.3f}s"
            )
            
            # å¤„ç†è¾¹ç•Œæ¡†ï¼šå°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åƒç´ åæ ‡
            h, w, _ = image_source.shape
            boxes = boxes * torch.Tensor([w, h, w, h])
            input_boxes = box_convert(boxes=boxes, in_fmt="cxcywh", out_fmt="xyxy").numpy()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹ç»“æœ
            if len(input_boxes) == 0:
                logger.info(
                    f"[{request_id}] âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ | "
                    f"ImageSize={w}x{h}"
                )
                return {
                    "status": "success",
                    "results": [],
                    "count": 0,
                    "image_shape": {
                        "width": w,
                        "height": h
                    },
                    "message": "æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡"
                }
            
            # ==============================
            # é˜¶æ®µ Dï¼šSAM2 åˆ†å‰²ï¼ˆæ¡†â†’maskï¼‰
            # ==============================
            stage_start = time.time()
            logger.info(
                f"[{request_id}] ğŸ¯ é˜¶æ®µ4: SAM2åˆ†å‰² | "
                f"Boxes={len(input_boxes)} | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆbfloat16ï¼‰
            if torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8:
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
            
            # SAM2åˆ†å‰²
            with torch.autocast(device_type=self.device, dtype=torch.bfloat16):
                masks, scores, logits = self.sam2_predictor.predict(
                    point_coords=None,
                    point_labels=None,
                    box=input_boxes,
                    multimask_output=False,
                )
            
            segment_time = time.time() - stage_start
            logger.info(
                f"[{request_id}] âœ… SAM2åˆ†å‰²å®Œæˆ | "
                f"Masks={len(masks) if hasattr(masks, '__len__') else 'N/A'} | "
                f"Duration={segment_time:.3f}s"
            )
            
            # è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆå¦‚æœæ˜¯ torch.Tensorï¼‰
            if isinstance(masks, torch.Tensor):
                masks = masks.cpu().numpy()
            if isinstance(scores, torch.Tensor):
                scores = scores.cpu().numpy()
            
            # æ¸…ç†GPUæ˜¾å­˜ï¼šé‡Šæ”¾æ¨ç†è¿‡ç¨‹ä¸­çš„ä¸´æ—¶tensor
            # æ³¨æ„ï¼šä¸è¦æ¸…ç†SAM2çš„_featuresï¼Œå› ä¸ºä¸‹æ¬¡æ¨ç†è¿˜éœ€è¦ä½¿ç”¨
            # åªéœ€è¦æ¸…ç†PyTorchçš„ç¼“å­˜å³å¯
            if torch.cuda.is_available():
                torch.cuda.empty_cache()  # æ¸…ç†PyTorchçš„æœªä½¿ç”¨ç¼“å­˜
            
            # å¤„ç†å¤šmaskè¾“å‡ºï¼ˆå‚è€ƒ grounded_sam2_local_demo.pyï¼‰
            # å¦‚æœ multimask_output=Trueï¼Œmasks å½¢çŠ¶ä¸º (n, 3, H, W)ï¼Œéœ€è¦é€‰æ‹©æœ€ä½³mask
            if masks.ndim == 4 and masks.shape[1] > 1:
                # å¤šmaskè¾“å‡ºæƒ…å†µï¼šé€‰æ‹©æœ€ä½³mask
                best = np.argmax(scores, axis=1)
                masks = masks[np.arange(masks.shape[0]), best]
            
            # è½¬æ¢ä¸º (n, H, W) æ ¼å¼
            # å¦‚æœè¿˜æœ‰å¤šä½™çš„ç»´åº¦ï¼Œä½¿ç”¨ squeeze
            if masks.ndim == 4:
                masks = masks.squeeze(1)
            elif masks.ndim == 2:
                # å¦‚æœåªæœ‰ä¸€ä¸ªmaskï¼Œæ·»åŠ batchç»´åº¦
                masks = masks[np.newaxis, :, :]
            
            # ç¡®ä¿ masks æ˜¯ 3ç»´æ•°ç»„ (n, H, W)
            assert masks.ndim == 3, f"masks åº”è¯¥æ˜¯3ç»´æ•°ç»„ (n, H, W)ï¼Œä½†å¾—åˆ° {masks.ndim} ç»´ï¼Œå½¢çŠ¶: {masks.shape}"
            
            # ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
            n_masks = masks.shape[0]
            n_boxes = len(input_boxes)
            n_labels = len(labels)
            n_confidences = len(confidences)
            
            if not (n_masks == n_boxes == n_labels == n_confidences):
                logger.warning(f"æ•°ç»„é•¿åº¦ä¸ä¸€è‡´: masks={n_masks}, boxes={n_boxes}, labels={n_labels}, confidences={n_confidences}")
                # å–æœ€å°é•¿åº¦ï¼Œç¡®ä¿ä¸ä¼šç´¢å¼•è¶Šç•Œ
                min_len = min(n_masks, n_boxes, n_labels, n_confidences)
                masks = masks[:min_len]
                input_boxes = input_boxes[:min_len]
                labels = labels[:min_len]
                confidences = confidences[:min_len]
            # return {"masks": masks, "input_boxes": input_boxes, "labels": labels, "confidences": confidences}
            # ==============================
            # é˜¶æ®µ Eï¼šç»“æœæ ¼å¼åŒ–
            # ==============================
            stage_start = time.time()
            logger.info(f"[{request_id}] ğŸ“¦ é˜¶æ®µ5: æ ¼å¼åŒ–ç»“æœ | PID={os.getpid()} | TID={thread_id}")
            
            # è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼
            # masks: (n, H, W) -> è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œæ¯ä¸ªmaskæ˜¯å¸ƒå°”æ•°ç»„çš„åˆ—è¡¨
            masks_list = []
            for mask in masks:
                # å°†å¸ƒå°”æ•°ç»„è½¬æ¢ä¸ºæ•´æ•°åˆ—è¡¨ï¼ˆ0å’Œ1ï¼‰ï¼Œä¾¿äºä¼ è¾“
                masks_list.append(mask.astype(int).tolist())
            
            # input_boxes: (n, 4) -> è½¬æ¢ä¸ºåˆ—è¡¨
            input_boxes_list = input_boxes.tolist() if isinstance(input_boxes, np.ndarray) else list(input_boxes)
            
            # labels: è½¬æ¢ä¸ºåˆ—è¡¨
            labels_list = labels.tolist() if isinstance(labels, np.ndarray) else list(labels)
            
            # confidences: è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆç¡®ä¿æ˜¯Python floatç±»å‹ï¼‰
            confidences_list = []
            for conf in confidences:
                if isinstance(conf, (torch.Tensor, np.ndarray)):
                    conf = float(conf.item() if hasattr(conf, 'item') else conf)
                else:
                    conf = float(conf)
                confidences_list.append(conf)
            
            format_time = time.time() - stage_start
            
            # æœ€ç»ˆæ¸…ç†ï¼šé‡Šæ”¾æ‰€æœ‰ä¸´æ—¶å˜é‡
            del image_source, image, boxes, input_boxes, labels, confidences
            if torch.cuda.is_available():
                torch.cuda.empty_cache()  # å†æ¬¡æ¸…ç†ç¼“å­˜
            
            total_inference_time = time.time() - lock_start
            
            logger.info(
                f"[{request_id}] âœ… ç»“æœæ ¼å¼åŒ–å®Œæˆ | "
                f"Count={len(masks_list)} | "
                f"FormatTime={format_time:.3f}s | "
                f"TotalTime={total_inference_time:.3f}s | "
                f"PID={os.getpid()} | "
                f"TID={thread_id}"
            )
            
            return {
                "status": "success",
                "masks": masks_list,
                "input_boxes": input_boxes_list,
                "labels": labels_list,
                "confidences": confidences_list,
                "count": len(masks_list),
                "image_shape": {
                    "width": w,
                    "height": h
                }
            }
#         #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”return______________________________________________
#         # ==============================
#         # é˜¶æ®µ Fï¼šç»“æœå¤„ç†ä¸æ ¼å¼åŒ–
#         # ==============================
#         # è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼ï¼ˆå‚è€ƒ grounded_sam2_local_demo.py çš„å¤šè¾¹å½¢æ ¼å¼ï¼‰
#         results = []
#         for idx in range(len(masks)):
#             mask = masks[idx]
#             box = input_boxes[idx]
#             label = labels[idx]
#             confidence = confidences[idx]
            
#             # ç¡®ä¿ mask æ˜¯å¸ƒå°”ç±»å‹æˆ–å¯ä»¥è½¬æ¢ä¸ºå¸ƒå°”ç±»å‹
#             if isinstance(confidence, torch.Tensor):
#                 confidence = confidence.item() if confidence.numel() == 1 else float(confidence)
#             else:
#                 confidence = float(confidence)
            
#             # æå–å¤šè¾¹å½¢è½®å»“ï¼ˆä½¿ç”¨ä¸ grounded_sam2_local_demo.py ç›¸åŒçš„æ–¹æ³•ï¼‰
#             polygon = self._mask_to_polygon_json(mask, box, label, confidence, idx + 1, epsilon=epsilon)
            
#             if polygon is not None:
#                 results.append({
#                     "id": polygon.get("id"),
#                     "type": polygon.get("type"),
#                     "points": polygon.get("points"),
#                     "label": polygon.get("label"),
#                     "score": polygon.get("score"),
#                     "order": polygon.get("order"),
#                     "bbox": box.tolist() if isinstance(box, np.ndarray) else list(box)
#                 })
        
#         return {
#             "status": "success",
#             "results": results,
#             "count": len(results),
#             "image_shape": {
#                 "width": w,
#                 "height": h
#             }
#         }
        
#     except Exception as e:
#         logger.error(f"æ¨ç†å¤±è´¥: {e}")
#         import traceback
#         logger.error(traceback.format_exc())
#         return {"status": "error", "message": str(e)}

# def _mask_to_polygon_json(self, mask, box, label, score, order, epsilon=1.0):
#     """
#     å°† mask è½¬æ¢ä¸ºå‰ç«¯å¤šè¾¹å½¢ JSON æ ¼å¼ï¼ˆå‚è€ƒ grounded_sam2_local_demo.pyï¼‰
    
#     Args:
#         mask: å…¨å›¾å°ºå¯¸çš„å¸ƒå°” mask (H, W)
#         box: è¾¹ç•Œæ¡† (x1, y1, x2, y2) åŸå›¾åæ ‡ç³»
#         label: ç±»åˆ«æ ‡ç­¾
#         score: æ£€æµ‹æ¡†ç½®ä¿¡åº¦åˆ†æ•°
#         order: é¡ºåºç¼–å·
#         epsilon: å¤šè¾¹å½¢ç®€åŒ–ç²¾åº¦å‚æ•°
    
#     Returns:
#         polygon_json: å‰ç«¯å¤šè¾¹å½¢ JSON å¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æœ‰æ•ˆè½®å»“åˆ™è¿”å› None
#     """
#     try:
#         import cv2
#         import random
#         import string
        
#         def generate_random_id():
#             """ç”Ÿæˆéšæœº ID"""
#             chars = string.digits + string.ascii_lowercase
#             return ''.join(random.choices(chars, k=11))
        
#         def extract_mask_contour_from_box(mask, box):
#             """ä»å…¨å›¾ mask ä¸­æå–æ¡†å†…åŒºåŸŸçš„è½®å»“"""
#             # ç¡®ä¿ mask æ˜¯ numpy æ•°ç»„
#             if not isinstance(mask, np.ndarray):
#                 mask = np.array(mask)
            
#             # ç¡®ä¿ mask æ˜¯2ç»´æ•°ç»„
#             if mask.ndim != 2:
#                 if mask.ndim == 3:
#                     mask = mask.squeeze(0)
#                 else:
#                     raise ValueError(f"mask åº”è¯¥æ˜¯2ç»´æ•°ç»„ (H, W)ï¼Œä½†å¾—åˆ° {mask.ndim} ç»´ï¼Œå½¢çŠ¶: {mask.shape}")
            
#             # ç¡®ä¿ box æ˜¯ numpy æ•°ç»„å¹¶è½¬æ¢ä¸ºæ•´æ•°
#             if not isinstance(box, np.ndarray):
#                 box = np.array(box)
#             x1, y1, x2, y2 = box.astype(int)
            
#             # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
#             mask_h, mask_w = mask.shape
#             x1_actual = max(0, min(x1, mask_w - 1))
#             y1_actual = max(0, min(y1, mask_h - 1))
#             x2_actual = max(x1_actual + 1, min(x2, mask_w))
#             y2_actual = max(y1_actual + 1, min(y2, mask_h))
            
#             actual_box = np.array([x1_actual, y1_actual, x2_actual, y2_actual])
            
#             # æ£€æŸ¥è£å‰ªåŒºåŸŸæ˜¯å¦æœ‰æ•ˆ
#             if x2_actual <= x1_actual or y2_actual <= y1_actual:
#                 return [], actual_box
            
#             # è£å‰ªåˆ°æ¡†å†…åŒºåŸŸï¼ˆæ³¨æ„ï¼šmask ç´¢å¼•æ˜¯ [y, x] é¡ºåºï¼‰
#             box_mask = mask[y1_actual:y2_actual, x1_actual:x2_actual].astype(np.uint8) * 255
            
#             if box_mask.sum() == 0:
#                 return [], actual_box
            
#             # æå–è½®å»“ï¼ˆåªæå–å¤–éƒ¨è½®å»“ï¼‰
#             contours, _ = cv2.findContours(box_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            
#             contour_list = []
#             for contour in contours:
#                 if len(contour) >= 3:
#                     contour_2d = contour.reshape(-1, 2).astype(float)
#                     contour_list.append(contour_2d)
            
#             return contour_list, actual_box
        
#         def simplify_polygon(contour, epsilon=2.0):
#             """ä½¿ç”¨ Douglas-Peucker ç®—æ³•ç®€åŒ–å¤šè¾¹å½¢"""
#             # ç¡®ä¿ contour æ˜¯ numpy æ•°ç»„
#             if not isinstance(contour, np.ndarray):
#                 contour = np.array(contour)
            
#             # æ£€æŸ¥ contour æ˜¯å¦æœ‰æ•ˆ
#             if len(contour) < 3:
#                 return contour
            
#             # ç¡®ä¿ contour æ˜¯2ç»´æ•°ç»„ (N, 2)
#             if contour.ndim == 1:
#                 if len(contour) == 2:
#                     contour = contour.reshape(1, 2)
#                 else:
#                     raise ValueError(f"contour å½¢çŠ¶æ— æ•ˆ: {contour.shape}")
#             elif contour.ndim == 2:
#                 if contour.shape[1] != 2:
#                     raise ValueError(f"contour åº”è¯¥æ˜¯ (N, 2) å½¢çŠ¶ï¼Œä½†å¾—åˆ° {contour.shape}")
#             else:
#                 raise ValueError(f"contour åº”è¯¥æ˜¯2ç»´æ•°ç»„ï¼Œä½†å¾—åˆ° {contour.ndim} ç»´")
            
#             # è½¬æ¢ä¸ºæ•´æ•°ç±»å‹ï¼ˆOpenCV è¦æ±‚ï¼‰
#             contour_int = contour.astype(np.int32)
            
#             # è½¬æ¢ä¸º OpenCV è¦æ±‚çš„æ ¼å¼ (N, 1, 2)
#             if contour_int.ndim == 2:
#                 contour_int = contour_int.reshape(-1, 1, 2)
            
#             # è®¡ç®—ç®€åŒ–å‚æ•°
#             epsilon_val = epsilon * cv2.arcLength(contour_int, closed=True) / 100.0
            
#             # æ‰§è¡Œå¤šè¾¹å½¢ç®€åŒ–
#             simplified = cv2.approxPolyDP(contour_int, epsilon_val, closed=True)
            
#             # è½¬æ¢å› (N, 2) æ ¼å¼å¹¶è¿”å›æµ®ç‚¹ç±»å‹
#             if simplified.shape[0] == 0:
#                 return contour  # å¦‚æœç®€åŒ–åä¸ºç©ºï¼Œè¿”å›åŸå§‹è½®å»“
            
#             return simplified.reshape(-1, 2).astype(float)
        
#         def local_to_global_coords(local_points, box, actual_box):
#             """å°†æ¡†å±€éƒ¨åæ ‡ç³»è½¬æ¢ä¸ºåŸå›¾å…¨å±€åæ ‡ç³»"""
#             # ç¡®ä¿è¾“å…¥æ˜¯ numpy æ•°ç»„
#             if not isinstance(local_points, np.ndarray):
#                 local_points = np.array(local_points)
#             if not isinstance(box, np.ndarray):
#                 box = np.array(box)
#             if not isinstance(actual_box, np.ndarray):
#                 actual_box = np.array(actual_box)
            
#             # ç¡®ä¿ local_points æ˜¯2ç»´æ•°ç»„ (N, 2)
#             if local_points.ndim == 1:
#                 local_points = local_points.reshape(1, -1)
#             if local_points.shape[1] != 2:
#                 raise ValueError(f"local_points åº”è¯¥æ˜¯ (N, 2) å½¢çŠ¶ï¼Œä½†å¾—åˆ° {local_points.shape}")
            
#             x1_actual, y1_actual, x2_actual, y2_actual = actual_box.astype(float)
#             actual_box_w = x2_actual - x1_actual
#             actual_box_h = y2_actual - y1_actual
            
#             x1_orig, y1_orig, x2_orig, y2_orig = box.astype(float)
#             orig_box_w = x2_orig - x1_orig
#             orig_box_h = y2_orig - y1_orig
            
#             # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
#             global_points = local_points.copy()
            
#             if actual_box_w != orig_box_w or actual_box_h != orig_box_h:
#                 scale_x = orig_box_w / actual_box_w if actual_box_w > 0 else 1.0
#                 scale_y = orig_box_h / actual_box_h if actual_box_h > 0 else 1.0
#                 # å…ˆç¼©æ”¾
#                 global_points[:, 0] = local_points[:, 0] * scale_x
#                 global_points[:, 1] = local_points[:, 1] * scale_y
#                 # å†å¹³ç§»
#                 global_points[:, 0] = x1_orig + global_points[:, 0]
#                 global_points[:, 1] = y1_orig + global_points[:, 1]
#             else:
#                 # ç›´æ¥å¹³ç§»
#                 global_points[:, 0] = x1_orig + local_points[:, 0]
#                 global_points[:, 1] = y1_orig + local_points[:, 1]
            
#             return global_points
        
#         # æ­¥éª¤1: ä» mask æå–æ¡†å†…è½®å»“
#         contours, actual_box = extract_mask_contour_from_box(mask, box)
        
#         if not contours:
#             return None
        
#         # é€‰æ‹©æœ€å¤§çš„è½®å»“ä½œä¸ºä¸»è¦è½®å»“
#         main_contour = max(contours, key=len)
        
#         # æ­¥éª¤2: ç®€åŒ–è½®å»“
#         simplified_contour = simplify_polygon(main_contour, epsilon=epsilon)
        
#         # æ­¥éª¤3: å±€éƒ¨åæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡
#         global_points = local_to_global_coords(simplified_contour, box, actual_box)
        
#         # æ­¥éª¤4: ç»„è£…å‰ç«¯ JSON
#         polygon_id = generate_random_id()
#         points = [
#             {
#                 "id": generate_random_id(),
#                 "x": float(x),
#                 "y": float(y)
#             }
#             for x, y in global_points
#         ]
        
#         polygon_json = {
#             "id": polygon_id,
#             "type": "line",
#             "points": points,
#             "label": label,
#             "score": float(score),
#             "order": int(order)
#         }
        
#         return polygon_json
        
#     except Exception as e:
#         logger.error(f"å¤šè¾¹å½¢è½¬æ¢å¤±è´¥: {e}")
#         import traceback
#         logger.error(traceback.format_exc())
#         return None

# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
model_manager = ModelManager()